# =============================================================================
# BOLT.DIY ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env.local and fill in your API keys
# See README.md for detailed setup instructions

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Environment mode (development, production, test)
NODE_ENV=development

# Application port (defaults to 5173 for development, 3000 for production)
PORT=5173

# Logging level (debug, info, warn, error)
VITE_LOG_LEVEL=debug

# Default context window size for local models
DEFAULT_NUM_CTX=32768

# =============================================================================
# MAJOR AI PROVIDER API KEYS
# =============================================================================

# Anthropic Claude - Primary provider
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI GPT models - Primary provider
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini - Primary provider
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_GENERATIVE_AI_API_KEY=your_google_gemini_api_key_here

# =============================================================================
# SPECIALIZED AI PROVIDERS
# =============================================================================

# Groq (Fast inference models)
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Together AI (Fine-tuned models)
# Get your API key from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=your_together_api_key_here

# OpenRouter (Multi-provider routing)
# Get your API key from: https://openrouter.ai/keys
OPEN_ROUTER_API_KEY=your_openrouter_api_key_here

# =============================================================================
# INTERNATIONAL & SPECIALIZED PROVIDERS
# =============================================================================

# DeepSeek (Chinese models)
# Get your API key from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Moonshot AI / Kimi (Chinese models)
# Get your API key from: https://platform.moonshot.ai/console/api-keys
MOONSHOT_API_KEY=your_moonshot_api_key_here

# X.AI (Elon Musk's company)
# Get your API key from: https://console.x.ai/
XAI_API_KEY=your_xai_api_key_here

# =============================================================================
# EUROPEAN & ADDITIONAL PROVIDERS
# =============================================================================

# Mistral (European models)
# Get your API key from: https://console.mistral.ai/api-keys/
MISTRAL_API_KEY=your_mistral_api_key_here

# Cohere (Canadian models)
# Get your API key from: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=your_cohere_api_key_here

# Perplexity AI (Search-augmented models)
# Get your API key from: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# =============================================================================
# COMMUNITY & OPEN SOURCE PROVIDERS
# =============================================================================

# Hugging Face (Open source models)
# Get your API key from: https://huggingface.co/settings/tokens
HuggingFace_API_KEY=your_huggingface_api_key_here

# Hyperbolic (High-performance inference)
# Get your API key from: https://app.hyperbolic.xyz/settings
HYPERBOLIC_API_KEY=your_hyperbolic_api_key_here

# GitHub Models (GitHub-hosted OpenAI models)
# Get your Personal Access Token from: https://github.com/settings/tokens
# - Select "Fine-grained tokens" 
# - Set repository access to "All repositories" 
# - Enable "GitHub Models" permission
GITHUB_API_KEY=github_pat_your_personal_access_token_here

# =============================================================================
# LOCAL MODEL PROVIDERS
# =============================================================================

# Ollama (Local model server)
# DON'T USE http://localhost:11434 due to IPv6 issues
# USE: http://127.0.0.1:11434
OLLAMA_API_BASE_URL=http://127.0.0.1:11434

# LMStudio (Local model interface)
# Make sure to enable CORS in LMStudio
# DON'T USE http://localhost:1234 due to IPv6 issues
# USE: http://127.0.0.1:1234
LMSTUDIO_API_BASE_URL=http://127.0.0.1:1234

# =============================================================================
# COMPATIBLE API PROVIDERS
# =============================================================================

# OpenAI-compatible API (Any provider using OpenAI format)
OPENAI_LIKE_API_BASE_URL=your_openai_like_base_url_here
OPENAI_LIKE_API_KEY=your_openai_like_api_key_here

# =============================================================================
# CLOUD INFRASTRUCTURE PROVIDERS
# =============================================================================

# AWS Bedrock Configuration (JSON format)
# Get your credentials from: https://console.aws.amazon.com/iam/home
# Example: {"region": "us-east-1", "accessKeyId": "yourAccessKeyId", "secretAccessKey": "yourSecretAccessKey"}
AWS_BEDROCK_CONFIG=your_aws_bedrock_config_json_here

# =============================================================================
# THIRD-PARTY INTEGRATIONS
# =============================================================================

# GitHub Integration
# Personal Access Token for repository access
# Get from: https://github.com/settings/tokens
# Used for importing/cloning repositories and accessing private repos
VITE_GITHUB_ACCESS_TOKEN=your_github_personal_access_token_here

# GitHub Token Type ('classic' or 'fine-grained')
VITE_GITHUB_TOKEN_TYPE=classic

# Supabase Integration
# Database URL and API keys for Supabase projects
# STEP 1: Go to https://supabase.com/dashboard
# STEP 2: Select your project → Settings → API
# STEP 3: Copy the following values:
# - Project URL: Copy the "Project URL" (e.g., https://abcdefghijk.supabase.co)
# - Anon Key: Copy the "anon/public" key (safe for client-side)
# - Access Token: Generate from https://supabase.com/dashboard/account/tokens (server-side only)
VITE_SUPABASE_URL=https://your-project-id.supabase.co
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key_here
VITE_SUPABASE_ACCESS_TOKEN=your_supabase_access_token_here

# Vercel Integration
# Access token for Vercel deployments and project management
# STEP 1: Go to https://vercel.com/account/tokens
# STEP 2: Create a new token with appropriate permissions
# STEP 3: Copy the generated token
VITE_VERCEL_ACCESS_TOKEN=your_vercel_access_token_here

# Netlify Deployment
# Get your access token from: https://app.netlify.com/user/applications
VITE_NETLIFY_ACCESS_TOKEN=your_netlify_access_token_here

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================
# 1. Copy this file to .env.local: cp .env.example .env.local
# 2. Fill in the API keys for the providers you want to use
# 3. For Supabase: Make sure to use your actual project URL and keys
# 4. For Vercel: Generate a token with project access permissions
# 5. Restart your development server: pnpm run dev
# 6. Go to Settings > Providers to enable/configure providers
# 
# SECURITY NOTE: Never commit .env.local to version control!
