# =============================================================================
# BOLT.DIY PRODUCTION ENVIRONMENT CONFIGURATION
# =============================================================================
# Rename this file to .env once you have filled in the required values
# This file should contain production-ready API keys and configuration

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Environment mode (must be 'production' for production deployment)
NODE_ENV=production

# Application port (defaults to 5173 for development, 3000 for production)
PORT=3000

# Logging level (warn, error for production)
VITE_LOG_LEVEL=warn

# Default context window size for local models
DEFAULT_NUM_CTX=32768

# =============================================================================
# MAJOR AI PROVIDER API KEYS
# =============================================================================

# Anthropic Claude - Primary provider
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# OpenAI GPT models - Primary provider
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Google Gemini - Primary provider
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_GENERATIVE_AI_API_KEY=

# =============================================================================
# SPECIALIZED AI PROVIDERS
# =============================================================================

# Groq (Fast inference models)
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=

# Together AI (Fine-tuned models)
# Get your API key from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=

# OpenRouter (Multi-provider routing)
# Get your API key from: https://openrouter.ai/keys
OPEN_ROUTER_API_KEY=

# =============================================================================
# INTERNATIONAL & SPECIALIZED PROVIDERS
# =============================================================================

# DeepSeek (Chinese models)
# Get your API key from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=

# Moonshot AI / Kimi (Chinese models)
# Get your API key from: https://platform.moonshot.ai/console/api-keys
MOONSHOT_API_KEY=

# X.AI (Elon Musk's company)
# Get your API key from: https://console.x.ai/
XAI_API_KEY=

# =============================================================================
# EUROPEAN & ADDITIONAL PROVIDERS
# =============================================================================

# Mistral (European models)
# Get your API key from: https://console.mistral.ai/api-keys/
MISTRAL_API_KEY=

# Cohere (Canadian models)
# Get your API key from: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=

# Perplexity AI (Search-augmented models)
# Get your API key from: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=

# =============================================================================
# COMMUNITY & OPEN SOURCE PROVIDERS
# =============================================================================

# Hugging Face (Open source models)
# Get your API key from: https://huggingface.co/settings/tokens
HuggingFace_API_KEY=

# Hyperbolic (High-performance inference)
# Get your API key from: https://app.hyperbolic.xyz/settings
HYPERBOLIC_API_KEY=

# GitHub Models (GitHub-hosted OpenAI models)
# Get your Personal Access Token from: https://github.com/settings/tokens
GITHUB_API_KEY=

# =============================================================================
# LOCAL MODEL PROVIDERS
# =============================================================================

# Ollama (Local model server)
# DON'T USE http://localhost:11434 due to IPv6 issues
# USE: http://127.0.0.1:11434
OLLAMA_API_BASE_URL=

# LMStudio (Local model interface)
# Make sure to enable CORS in LMStudio
LMSTUDIO_API_BASE_URL=

# =============================================================================
# COMPATIBLE API PROVIDERS
# =============================================================================

# OpenAI-compatible API (Any provider using OpenAI format)
OPENAI_LIKE_API_BASE_URL=
OPENAI_LIKE_API_KEY=

# =============================================================================
# CLOUD INFRASTRUCTURE PROVIDERS
# =============================================================================

# AWS Bedrock Configuration (JSON format)
# Get your credentials from: https://console.aws.amazon.com/iam/home
# Example: {"region": "us-east-1", "accessKeyId": "yourAccessKeyId", "secretAccessKey": "yourSecretAccessKey"}
AWS_BEDROCK_CONFIG=

# =============================================================================
# THIRD-PARTY INTEGRATIONS
# =============================================================================

# GitHub Integration
# Personal Access Token for repository access
VITE_GITHUB_ACCESS_TOKEN=
VITE_GITHUB_TOKEN_TYPE=classic

# Supabase Integration
# Database URL and API keys for Supabase projects
# IMPORTANT: Use production-ready API keys, not development keys
# - Project URL: Your production Supabase project URL
# - Anon Key: Production anon/public key (safe for client-side)
# - Access Token: Production service role key (keep secure, server-side only)
VITE_SUPABASE_URL=
VITE_SUPABASE_ANON_KEY=
VITE_SUPABASE_ACCESS_TOKEN=

# Vercel Integration
# Access token for Vercel deployments and project management
# IMPORTANT: Use production token with appropriate permissions
VITE_VERCEL_ACCESS_TOKEN=

# Netlify Deployment
VITE_NETLIFY_ACCESS_TOKEN=

# =============================================================================
# PRODUCTION CONTEXT WINDOW EXAMPLES
# =============================================================================
# Example values for different model configurations:
#
# qwen2.5-coder:32b context window sizes:
# DEFAULT_NUM_CTX=32768  # Consumes ~36GB VRAM
# DEFAULT_NUM_CTX=24576  # Consumes ~32GB VRAM
# DEFAULT_NUM_CTX=12288  # Consumes ~26GB VRAM
# DEFAULT_NUM_CTX=6144   # Consumes ~24GB VRAM

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================
# 1. Fill in the API keys for the providers you want to use in production
# 2. Rename this file to .env: mv .env.production .env
# 3. Verify all required keys are set before deployment
# 4. Test the application thoroughly in a staging environment first
#
# SECURITY NOTES:
# - Never commit production API keys to version control
# - Use environment-specific keys for production
# - Rotate keys regularly for security
# - Monitor usage and costs for all providers
